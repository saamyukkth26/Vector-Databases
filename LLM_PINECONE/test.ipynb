{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure with explicit API key - don't rely on environment variables\n",
    "PINECONE_API_KEY = \"pcsk_RwHoN_ArFYtHrRoYrHgmHchWofZJShCjkigHbAQpicr5Xwd4GJdqW9PGyxbkVuUaVjZu4\"\n",
    "INDEX_NAME = \"langchainvector\"\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read PDF documents\n",
    "def read_documents(directory):\n",
    "    print(f\"Loading documents from {directory}...\")\n",
    "    loader = PyPDFDirectoryLoader(directory)\n",
    "    documents = loader.load()\n",
    "    print(f\"Loaded {len(documents)} documents\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to chunk documents\n",
    "def chunk_documents(documents, chunk_size=800, chunk_overlap=50):\n",
    "    print(\"Chunking documents...\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Created {len(chunks)} chunks\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone\n",
    "def setup_pinecone():\n",
    "    print(f\"Initializing Pinecone with API key: {PINECONE_API_KEY[:5]}...\")\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    \n",
    "    # Check if index exists\n",
    "    indexes = pc.list_indexes().names()\n",
    "    \n",
    "    if INDEX_NAME in indexes:\n",
    "        print(f\"Deleting existing index '{INDEX_NAME}'...\")\n",
    "        pc.delete_index(INDEX_NAME)\n",
    "        time.sleep(10)  # Wait longer for deletion to complete\n",
    "    \n",
    "    print(f\"Creating index '{INDEX_NAME}' with dimension 384...\")\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=384,  # Dimension for all-MiniLM-L6-v2\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    \n",
    "    # Wait for index to initialize\n",
    "    print(\"Waiting for index to initialize...\")\n",
    "    time.sleep(10)\n",
    "    \n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload documents to Pinecone using direct method\n",
    "def upload_to_pinecone(chunks, embedding_model):\n",
    "    print(\"Preparing to upload documents to Pinecone...\")\n",
    "    \n",
    "    # Initialize Pinecone\n",
    "    pc = setup_pinecone()\n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    \n",
    "    # Generate embeddings for chunks\n",
    "    print(\"Generating embeddings for chunks...\")\n",
    "    vectors_to_upsert = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Get the embedding for the chunk\n",
    "        try:\n",
    "            embedding = embedding_model.embed_documents([chunk.page_content])[0]\n",
    "            \n",
    "            # Create a vector with metadata\n",
    "            vector = {\n",
    "                \"id\": f\"doc_{i}\",\n",
    "                \"values\": embedding,\n",
    "                \"metadata\": {\n",
    "                    \"text\": chunk.page_content,\n",
    "                    \"source\": chunk.metadata.get(\"source\", \"unknown\")\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            vectors_to_upsert.append(vector)\n",
    "            \n",
    "            # Print progress\n",
    "            if (i + 1) % 20 == 0 or i == len(chunks) - 1:\n",
    "                print(f\"Processed {i + 1}/{len(chunks)} chunks\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding chunk {i}: {e}\")\n",
    "         # Upload vectors in batches\n",
    "    batch_size = 100\n",
    "    for i in range(0, len(vectors_to_upsert), batch_size):\n",
    "        batch = vectors_to_upsert[i:i + batch_size]\n",
    "        try:\n",
    "            index.upsert(vectors=batch)\n",
    "            print(f\"Uploaded batch {i//batch_size + 1}/{(len(vectors_to_upsert)-1)//batch_size + 1}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading batch {i//batch_size + 1}: {e}\")\n",
    "    \n",
    "    # Verify upload\n",
    "    stats = index.describe_index_stats()\n",
    "    print(f\"Index stats after upload: {stats}\")\n",
    "    print(f\"Total vectors in index: {stats.get('total_vector_count', 'unknown')}\")\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query function\n",
    "def query_pinecone(index, embedding_model, query_text, top_k=3):\n",
    "    print(f\"Querying Pinecone with: '{query_text}'\")\n",
    "    \n",
    "    # Generate query embedding\n",
    "    query_embedding = embedding_model.embed_query(query_text)\n",
    "    \n",
    "    # Query Pinecone\n",
    "    results = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from documents/...\n",
      "Loaded 58 documents\n",
      "Chunking documents...\n",
      "Created 140 chunks\n",
      "Initializing embedding model: all-MiniLM-L6-v2\n",
      "Preparing to upload documents to Pinecone...\n",
      "Initializing Pinecone with API key: pcsk_...\n",
      "Deleting existing index 'langchainvector'...\n",
      "Creating index 'langchainvector' with dimension 384...\n",
      "Waiting for index to initialize...\n",
      "Generating embeddings for chunks...\n",
      "Processed 20/140 chunks\n",
      "Processed 40/140 chunks\n",
      "Processed 60/140 chunks\n",
      "Processed 80/140 chunks\n",
      "Processed 100/140 chunks\n",
      "Processed 120/140 chunks\n",
      "Processed 140/140 chunks\n",
      "Uploaded batch 1/2\n",
      "Uploaded batch 2/2\n",
      "Index stats after upload: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0,\n",
      " 'vector_type': 'dense'}\n",
      "Total vectors in index: 0\n",
      "Querying Pinecone with: 'what budget is being talked about?'\n",
      "\n",
      "Query Results:\n",
      "No results found for the query.\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Load documents\n",
    "    documents = read_documents('documents/')\n",
    "    \n",
    "    # Step 2: Chunk documents\n",
    "    chunks = chunk_documents(documents)\n",
    "    \n",
    "    # Step 3: Initialize embedding model\n",
    "    print(f\"Initializing embedding model: {MODEL_NAME}\")\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=MODEL_NAME)\n",
    "    \n",
    "    # Step 4: Upload to Pinecone\n",
    "    index = upload_to_pinecone(chunks, embedding_model)\n",
    "    \n",
    "    # Step 5: Query\n",
    "    query_text = \"what budget is being talked about?\"\n",
    "    results = query_pinecone(index, embedding_model, query_text)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nQuery Results:\")\n",
    "    if results and results.get('matches'):\n",
    "        for i, match in enumerate(results['matches']):\n",
    "            print(f\"\\nResult {i+1} (Score: {match['score']:.4f}):\")\n",
    "            print(f\"Content: {match['metadata']['text'][:150]}...\")\n",
    "            print(f\"Source: {match['metadata'].get('source', 'Unknown')}\")\n",
    "    else:\n",
    "        print(\"No results found for the query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying Pinecone with: 'Indirect taxes on?'\n",
      "\n",
      "Query Results:\n",
      "\n",
      "Result 1 (Score: 0.6875):\n",
      "Content:  Rationalisation  \n",
      " Others  \n",
      " Personal Income Tax  \n",
      "  \n",
      "Annexures 35 \n",
      " Annexure to Part B of the Budget Speech 2023-24 \n",
      "i. Amendments relating to D...\n",
      "Source: documents/budget_speech.pdf\n",
      "\n",
      "Result 2 (Score: 0.5614):\n",
      "Content: 27 \n",
      " \n",
      " \n",
      " \n",
      "PART B \n",
      "Indirect Taxes \n",
      "118. My indirect tax proposals aim to promote exports, boost domestic \n",
      "manufacturing, enhance domestic value additio...\n",
      "Source: documents/budget_speech.pdf\n",
      "\n",
      "Result 3 (Score: 0.5461):\n",
      "Content: 35 \n",
      " \n",
      " \n",
      " \n",
      "Annexure to Part B of the Budget Speech 2023-24 \n",
      "Amendments relating to Direct Taxes \n",
      "A. PROVIDING TAX RELIEF UNDER NEW PERSONAL TAX REGIME ...\n",
      "Source: documents/budget_speech.pdf\n"
     ]
    }
   ],
   "source": [
    "query_text = \"Indirect taxes on?\"\n",
    "results = query_pinecone(index, embedding_model, query_text)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nQuery Results:\")\n",
    "if results and results.get('matches'):\n",
    "    for i, match in enumerate(results['matches']):\n",
    "        print(f\"\\nResult {i+1} (Score: {match['score']:.4f}):\")\n",
    "        print(f\"Content: {match['metadata']['text'][:150]}...\")\n",
    "        print(f\"Source: {match['metadata'].get('source', 'Unknown')}\")\n",
    "else:\n",
    "    print(\"No results found for the query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
